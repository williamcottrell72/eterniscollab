{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buzz Distribution Analysis\n",
    "\n",
    "This notebook analyzes the distribution of interest and divisiveness scores from different LLM providers (OpenAI vs Claude) at different temperature settings.\n",
    "\n",
    "We'll explore:\n",
    "1. How temperature affects the variability of interest and divisiveness scores\n",
    "2. Differences between OpenAI and Claude's assessments\n",
    "3. Visual comparison of score distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from buzz import query_interest_openrouter, query_divisiveness_openrouter\n",
    "\n",
    "# Ensure OpenRouter API key is set\n",
    "assert os.environ.get('OPENROUTER_API_KEY'), \"OPENROUTER_API_KEY not set\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic to analyze\n",
    "TOPIC = \"Should Donald Trump win the nobel peace price?\"\n",
    "\n",
    "# Number of samples to collect for each configuration\n",
    "N_SAMPLES = 20\n",
    "\n",
    "# Temperature settings to compare\n",
    "LOW_TEMP = 0.3\n",
    "HIGH_TEMP = 0.9\n",
    "\n",
    "# API key from environment\n",
    "OPENROUTER_KEY = os.environ.get('OPENROUTER_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_interest_samples(topic, model, api_key, temperature, n_samples):\n",
    "    \"\"\"Collect interest score samples from OpenRouter.\"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        try:\n",
    "            score = query_interest_openrouter(topic, model, api_key, temperature=temperature)\n",
    "            scores.append(score)\n",
    "            print(f\"  Sample {i+1}/{n_samples}: {score:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error on sample {i+1}: {str(e)}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def collect_divisiveness_samples(topic, model, api_key, temperature, n_samples):\n",
    "    \"\"\"Collect divisiveness score samples from OpenRouter.\"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        try:\n",
    "            score = query_divisiveness_openrouter(topic, model, api_key, temperature=temperature)\n",
    "            scores.append(score)\n",
    "            print(f\"  Sample {i+1}/{n_samples}: {score:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error on sample {i+1}: {str(e)}\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Interest Scores\n",
    "\n",
    "We'll collect interest scores from both providers at low and high temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting INTEREST scores for topic: Should Donald Trump win the nobel peace price?\n",
      "\n",
      "OpenAI - Low Temperature (0.3):\n",
      "  Sample 1/20: 0.450\n",
      "  Sample 2/20: 0.550\n",
      "  Sample 3/20: 0.450\n",
      "  Sample 4/20: 0.450\n",
      "  Sample 5/20: 0.450\n",
      "  Sample 6/20: 0.450\n",
      "  Sample 7/20: 0.450\n",
      "  Sample 8/20: 0.450\n",
      "  Sample 9/20: 0.550\n",
      "  Sample 10/20: 0.550\n",
      "  Sample 11/20: 0.550\n",
      "  Sample 12/20: 0.550\n",
      "  Sample 13/20: 0.450\n",
      "  Sample 14/20: 0.550\n",
      "  Sample 15/20: 0.550\n",
      "  Sample 16/20: 0.550\n",
      "  Sample 17/20: 0.350\n",
      "  Sample 18/20: 0.450\n",
      "  Sample 19/20: 0.450\n",
      "  Sample 20/20: 0.550\n",
      "\n",
      "OpenAI - High Temperature (0.9):\n",
      "  Sample 1/20: 0.450\n",
      "  Sample 2/20: 0.350\n",
      "  Sample 3/20: 0.450\n",
      "  Sample 4/20: 0.450\n",
      "  Sample 5/20: 0.350\n",
      "  Sample 6/20: 0.530\n",
      "  Sample 7/20: 0.550\n",
      "  Sample 8/20: 0.550\n",
      "  Sample 9/20: 0.450\n",
      "  Sample 10/20: 0.450\n",
      "  Sample 11/20: 0.550\n",
      "  Sample 12/20: 0.500\n",
      "  Sample 13/20: 0.550\n",
      "  Sample 14/20: 0.520\n",
      "  Sample 15/20: 0.550\n",
      "  Sample 16/20: 0.480\n",
      "  Sample 17/20: 0.350\n",
      "  Sample 18/20: 0.350\n"
     ]
    }
   ],
   "source": [
    "print(f\"Collecting INTEREST scores for topic: {TOPIC}\\n\")\n",
    "\n",
    "print(\"OpenAI - Low Temperature (0.3):\")\n",
    "interest_openai_low = collect_interest_samples(TOPIC, \"openai/gpt-4o-mini\", OPENROUTER_KEY, LOW_TEMP, N_SAMPLES)\n",
    "\n",
    "print(\"\\nOpenAI - High Temperature (0.9):\")\n",
    "interest_openai_high = collect_interest_samples(TOPIC, \"openai/gpt-4o-mini\", OPENROUTER_KEY, HIGH_TEMP, N_SAMPLES)\n",
    "\n",
    "print(\"\\nClaude - Low Temperature (0.3):\")\n",
    "interest_claude_low = collect_interest_samples(TOPIC, \"anthropic/claude-sonnet-4\", OPENROUTER_KEY, LOW_TEMP, N_SAMPLES)\n",
    "\n",
    "print(\"\\nClaude - High Temperature (0.9):\")\n",
    "interest_claude_high = collect_interest_samples(TOPIC, \"anthropic/claude-sonnet-4\", OPENROUTER_KEY, HIGH_TEMP, N_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Divisiveness Scores\n",
    "\n",
    "Now we'll collect divisiveness scores from both providers at low and high temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\\nCollecting DIVISIVENESS scores for topic: {TOPIC}\\n\")\n",
    "\n",
    "print(\"OpenAI - Low Temperature (0.3):\")\n",
    "div_openai_low = collect_divisiveness_samples(TOPIC, \"openai/gpt-4o-mini\", OPENROUTER_KEY, LOW_TEMP, N_SAMPLES)\n",
    "\n",
    "print(\"\\nOpenAI - High Temperature (0.9):\")\n",
    "div_openai_high = collect_divisiveness_samples(TOPIC, \"openai/gpt-4o-mini\", OPENROUTER_KEY, HIGH_TEMP, N_SAMPLES)\n",
    "\n",
    "print(\"\\nClaude - Low Temperature (0.3):\")\n",
    "div_claude_low = collect_divisiveness_samples(TOPIC, \"anthropic/claude-sonnet-4\", OPENROUTER_KEY, LOW_TEMP, N_SAMPLES)\n",
    "\n",
    "print(\"\\nClaude - High Temperature (0.9):\")\n",
    "div_claude_high = collect_divisiveness_samples(TOPIC, \"anthropic/claude-sonnet-4\", OPENROUTER_KEY, HIGH_TEMP, N_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for interest scores\n",
    "interest_data = {\n",
    "    'OpenAI Low Temp': interest_openai_low,\n",
    "    'OpenAI High Temp': interest_openai_high,\n",
    "    'Claude Low Temp': interest_claude_low,\n",
    "    'Claude High Temp': interest_claude_high\n",
    "}\n",
    "\n",
    "interest_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in interest_data.items()]))\n",
    "\n",
    "print(\"\\n=== INTEREST SCORE STATISTICS ===\")\n",
    "print(interest_df.describe())\n",
    "\n",
    "# Create DataFrame for divisiveness scores\n",
    "div_data = {\n",
    "    'OpenAI Low Temp': div_openai_low,\n",
    "    'OpenAI High Temp': div_openai_high,\n",
    "    'Claude Low Temp': div_claude_low,\n",
    "    'Claude High Temp': div_claude_high\n",
    "}\n",
    "\n",
    "div_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in div_data.items()]))\n",
    "\n",
    "print(\"\\n=== DIVISIVENESS SCORE STATISTICS ===\")\n",
    "print(div_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Interest Score Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create histograms for interest scores with larger size and better fonts\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=(\n        'OpenAI - Low Temp (0.3)',\n        'OpenAI - High Temp (0.9)',\n        'Claude - Low Temp (0.3)',\n        'Claude - High Temp (0.9)'\n    ),\n    vertical_spacing=0.15,\n    horizontal_spacing=0.12\n)\n\n# Add histograms\nfig.add_trace(\n    go.Histogram(x=interest_openai_low, name='OpenAI Low', marker_color='lightblue', nbinsx=15),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Histogram(x=interest_openai_high, name='OpenAI High', marker_color='darkblue', nbinsx=15),\n    row=1, col=2\n)\nfig.add_trace(\n    go.Histogram(x=interest_claude_low, name='Claude Low', marker_color='lightgreen', nbinsx=15),\n    row=2, col=1\n)\nfig.add_trace(\n    go.Histogram(x=interest_claude_high, name='Claude High', marker_color='darkgreen', nbinsx=15),\n    row=2, col=2\n)\n\n# Update layout with larger size and fonts\nfig.update_xaxes(title_text=\"Interest Score\", range=[0, 1], title_font_size=16, tickfont_size=14)\nfig.update_yaxes(title_text=\"Frequency\", title_font_size=16, tickfont_size=14)\nfig.update_layout(\n    height=1000,  # Increased from 700\n    width=1400,   # Added width\n    title_text=f\"Interest Score Distributions: {TOPIC}\",\n    title_font_size=20,\n    showlegend=False,\n    font=dict(size=14)\n)\n\n# Update subplot titles font size\nfor annotation in fig['layout']['annotations']:\n    annotation['font'] = dict(size=16)\n\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Divisiveness Score Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create histograms for divisiveness scores with larger size and better fonts\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=(\n        'OpenAI - Low Temp (0.3)',\n        'OpenAI - High Temp (0.9)',\n        'Claude - Low Temp (0.3)',\n        'Claude - High Temp (0.9)'\n    ),\n    vertical_spacing=0.15,\n    horizontal_spacing=0.12\n)\n\n# Add histograms\nfig.add_trace(\n    go.Histogram(x=div_openai_low, name='OpenAI Low', marker_color='lightcoral', nbinsx=15),\n    row=1, col=1\n)\nfig.add_trace(\n    go.Histogram(x=div_openai_high, name='OpenAI High', marker_color='darkred', nbinsx=15),\n    row=1, col=2\n)\nfig.add_trace(\n    go.Histogram(x=div_claude_low, name='Claude Low', marker_color='lightyellow', nbinsx=15),\n    row=2, col=1\n)\nfig.add_trace(\n    go.Histogram(x=div_claude_high, name='Claude High', marker_color='orange', nbinsx=15),\n    row=2, col=2\n)\n\n# Update layout with larger size and fonts\nfig.update_xaxes(title_text=\"Divisiveness Score\", range=[0, 1], title_font_size=16, tickfont_size=14)\nfig.update_yaxes(title_text=\"Frequency\", title_font_size=16, tickfont_size=14)\nfig.update_layout(\n    height=1000,  # Increased from 700\n    width=1400,   # Added width\n    title_text=f\"Divisiveness Score Distributions: {TOPIC}\",\n    title_font_size=20,\n    showlegend=False,\n    font=dict(size=14)\n)\n\n# Update subplot titles font size\nfor annotation in fig['layout']['annotations']:\n    annotation['font'] = dict(size=16)\n\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot Comparison: Interest Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare data for box plot\ninterest_plot_data = []\nfor config, scores in interest_data.items():\n    for score in scores:\n        provider = 'OpenAI' if 'OpenAI' in config else 'Claude'\n        temp = 'Low (0.3)' if 'Low' in config else 'High (0.9)'\n        interest_plot_data.append({\n            'Score': score,\n            'Provider': provider,\n            'Temperature': temp,\n            'Config': config\n        })\n\ninterest_plot_df = pd.DataFrame(interest_plot_data)\n\nfig = px.box(\n    interest_plot_df,\n    x='Temperature',\n    y='Score',\n    color='Provider',\n    title=f'Interest Score Comparison: {TOPIC}',\n    labels={'Score': 'Interest Score (0-1)'},\n    points='all'\n)\n\n# Increase size and font sizes\nfig.update_layout(\n    height=700,  # Increased from 500\n    width=1200,  # Added width\n    yaxis_range=[0, 1],\n    title_font_size=20,\n    font=dict(size=14),\n    xaxis=dict(title_font_size=16, tickfont_size=14),\n    yaxis=dict(title_font_size=16, tickfont_size=14),\n    legend=dict(font=dict(size=14))\n)\n\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot Comparison: Divisiveness Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare data for box plot\ndiv_plot_data = []\nfor config, scores in div_data.items():\n    for score in scores:\n        provider = 'OpenAI' if 'OpenAI' in config else 'Claude'\n        temp = 'Low (0.3)' if 'Low' in config else 'High (0.9)'\n        div_plot_data.append({\n            'Score': score,\n            'Provider': provider,\n            'Temperature': temp,\n            'Config': config\n        })\n\ndiv_plot_df = pd.DataFrame(div_plot_data)\n\nfig = px.box(\n    div_plot_df,\n    x='Temperature',\n    y='Score',\n    color='Provider',\n    title=f'Divisiveness Score Comparison: {TOPIC}',\n    labels={'Score': 'Divisiveness Score (0-1)'},\n    points='all'\n)\n\n# Increase size and font sizes\nfig.update_layout(\n    height=700,  # Increased from 500\n    width=1200,  # Added width\n    yaxis_range=[0, 1],\n    title_font_size=20,\n    font=dict(size=14),\n    xaxis=dict(title_font_size=16, tickfont_size=14),\n    yaxis=dict(title_font_size=16, tickfont_size=14),\n    legend=dict(font=dict(size=14))\n)\n\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot: Interest vs Divisiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create scatter plot comparing interest and divisiveness\nscatter_data = []\n\nconfigs = [\n    ('OpenAI Low', interest_openai_low, div_openai_low),\n    ('OpenAI High', interest_openai_high, div_openai_high),\n    ('Claude Low', interest_claude_low, div_claude_low),\n    ('Claude High', interest_claude_high, div_claude_high)\n]\n\nfor config_name, interest_scores, div_scores in configs:\n    for i, d in zip(interest_scores, div_scores):\n        scatter_data.append({\n            'Interest': i,\n            'Divisiveness': d,\n            'Buzz': i * d,  # Combined buzz score\n            'Config': config_name\n        })\n\nscatter_df = pd.DataFrame(scatter_data)\n\nfig = px.scatter(\n    scatter_df,\n    x='Interest',\n    y='Divisiveness',\n    color='Config',\n    size='Buzz',\n    title=f'Interest vs Divisiveness: {TOPIC}',\n    labels={'Interest': 'Interest Score', 'Divisiveness': 'Divisiveness Score'},\n    hover_data=['Buzz']\n)\n\n# Increase size and font sizes\nfig.update_layout(\n    height=800,   # Increased from 600\n    width=1200,   # Added width\n    title_font_size=20,\n    font=dict(size=14),\n    xaxis=dict(title_font_size=16, tickfont_size=14),\n    yaxis=dict(title_font_size=16, tickfont_size=14),\n    legend=dict(font=dict(size=14))\n)\n\nfig.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== VARIANCE ANALYSIS ===\")\n",
    "print(\"\\nInterest Scores - Standard Deviation:\")\n",
    "for config, scores in interest_data.items():\n",
    "    print(f\"  {config:25s}: {np.std(scores):.4f}\")\n",
    "\n",
    "print(\"\\nDivisiveness Scores - Standard Deviation:\")\n",
    "for config, scores in div_data.items():\n",
    "    print(f\"  {config:25s}: {np.std(scores):.4f}\")\n",
    "\n",
    "print(\"\\nVariance Ratio (High Temp / Low Temp):\")\n",
    "interest_openai_ratio = np.std(interest_openai_high) / np.std(interest_openai_low) if np.std(interest_openai_low) > 0 else float('inf')\n",
    "interest_claude_ratio = np.std(interest_claude_high) / np.std(interest_claude_low) if np.std(interest_claude_low) > 0 else float('inf')\n",
    "div_openai_ratio = np.std(div_openai_high) / np.std(div_openai_low) if np.std(div_openai_low) > 0 else float('inf')\n",
    "div_claude_ratio = np.std(div_claude_high) / np.std(div_claude_low) if np.std(div_claude_low) > 0 else float('inf')\n",
    "\n",
    "print(f\"  OpenAI Interest:     {interest_openai_ratio:.2f}x\")\n",
    "print(f\"  Claude Interest:     {interest_claude_ratio:.2f}x\")\n",
    "print(f\"  OpenAI Divisiveness: {div_openai_ratio:.2f}x\")\n",
    "print(f\"  Claude Divisiveness: {div_claude_ratio:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "**Temperature Effects:**\n",
    "- Higher temperature should increase variance in scores\n",
    "- Check if this holds for both interest and divisiveness\n",
    "\n",
    "**Provider Differences:**\n",
    "- Compare mean scores between OpenAI and Claude\n",
    "- Check if providers have different baseline assessments\n",
    "- Examine if one provider is more sensitive to temperature\n",
    "\n",
    "**Interest vs Divisiveness:**\n",
    "- Are these metrics correlated?\n",
    "- Does the scatter plot show any clustering patterns?\n",
    "- How does the combined buzz score (interest Ã— divisiveness) vary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Topics\n",
    "\n",
    "Modify the `TOPIC` variable in the configuration cell and re-run all cells to analyze different topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested topics to try:\n",
    "# - \"Climate Change\"\n",
    "# - \"Artificial Intelligence\"\n",
    "# - \"Taylor Swift\"\n",
    "# - \"The Beatles\"\n",
    "# - \"Ukraine War\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}